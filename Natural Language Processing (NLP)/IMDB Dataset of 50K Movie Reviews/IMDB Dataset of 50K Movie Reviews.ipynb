{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824dbc2d-c1e9-4e43-89d1-1a21231e38f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wfi-7\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri yükleniyor...\n",
      "Model 1 (Klasik) eğitiliyor...\n",
      "Klasik Model Accuracy: 0.8797\n",
      "Model 2 (Deep Learning) eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wfi-7\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.5096 - loss: 0.6932 - val_accuracy: 0.5040 - val_loss: 0.6909\n",
      "Epoch 2/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.5638 - loss: 0.6803 - val_accuracy: 0.5610 - val_loss: 0.6828\n",
      "Epoch 3/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6193 - loss: 0.6723 - val_accuracy: 0.5810 - val_loss: 0.6711\n",
      "Epoch 4/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.5805 - loss: 0.6717 - val_accuracy: 0.6167 - val_loss: 0.6580\n",
      "Epoch 5/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6144 - loss: 0.6465 - val_accuracy: 0.6107 - val_loss: 0.6344\n",
      "Epoch 6/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6076 - loss: 0.6566 - val_accuracy: 0.5650 - val_loss: 0.6741\n",
      "Epoch 7/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.5974 - loss: 0.6517 - val_accuracy: 0.6297 - val_loss: 0.6368\n",
      "Epoch 8/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6330 - loss: 0.6160 - val_accuracy: 0.6657 - val_loss: 0.6215\n",
      "Epoch 9/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6187 - loss: 0.6479 - val_accuracy: 0.5753 - val_loss: 0.6645\n",
      "Epoch 10/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6152 - loss: 0.6169 - val_accuracy: 0.5377 - val_loss: 0.6883\n",
      "Epoch 11/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6297 - loss: 0.5850 - val_accuracy: 0.5847 - val_loss: 0.6677\n",
      "Epoch 12/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6403 - loss: 0.5633 - val_accuracy: 0.5947 - val_loss: 0.6623\n",
      "Epoch 13/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6765 - loss: 0.5353 - val_accuracy: 0.6723 - val_loss: 0.6858\n",
      "Epoch 14/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.7989 - loss: 0.4458 - val_accuracy: 0.7973 - val_loss: 0.5017\n",
      "Epoch 15/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8739 - loss: 0.3376 - val_accuracy: 0.8197 - val_loss: 0.4498\n",
      "Epoch 16/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9056 - loss: 0.2688 - val_accuracy: 0.8180 - val_loss: 0.4751\n",
      "Epoch 17/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9241 - loss: 0.2281 - val_accuracy: 0.8313 - val_loss: 0.4551\n",
      "Epoch 18/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9426 - loss: 0.1894 - val_accuracy: 0.8237 - val_loss: 0.4894\n",
      "Epoch 19/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9550 - loss: 0.1548 - val_accuracy: 0.8287 - val_loss: 0.5400\n",
      "Epoch 20/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9625 - loss: 0.1372 - val_accuracy: 0.8210 - val_loss: 0.6162\n",
      "Epoch 21/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9728 - loss: 0.1105 - val_accuracy: 0.8243 - val_loss: 0.6655\n",
      "Epoch 22/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9782 - loss: 0.0941 - val_accuracy: 0.8247 - val_loss: 0.6446\n",
      "Epoch 23/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9818 - loss: 0.0837 - val_accuracy: 0.8270 - val_loss: 0.6964\n",
      "Epoch 24/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9829 - loss: 0.0772 - val_accuracy: 0.8220 - val_loss: 0.7463\n",
      "Epoch 25/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9841 - loss: 0.0691 - val_accuracy: 0.8187 - val_loss: 0.7628\n",
      "Epoch 26/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9870 - loss: 0.0623 - val_accuracy: 0.8170 - val_loss: 0.8082\n",
      "Epoch 27/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9890 - loss: 0.0544 - val_accuracy: 0.8207 - val_loss: 0.8447\n",
      "Epoch 28/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9889 - loss: 0.0540 - val_accuracy: 0.8190 - val_loss: 0.8695\n",
      "Epoch 29/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9902 - loss: 0.0489 - val_accuracy: 0.8153 - val_loss: 0.8619\n",
      "Epoch 30/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9902 - loss: 0.0471 - val_accuracy: 0.8247 - val_loss: 0.8452\n",
      "Epoch 31/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9918 - loss: 0.0388 - val_accuracy: 0.8190 - val_loss: 0.9394\n",
      "Epoch 32/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9758 - loss: 0.0834 - val_accuracy: 0.8120 - val_loss: 0.8366\n",
      "Epoch 33/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9932 - loss: 0.0369 - val_accuracy: 0.8193 - val_loss: 0.8883\n",
      "Epoch 34/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9952 - loss: 0.0285 - val_accuracy: 0.8180 - val_loss: 0.8859\n",
      "Epoch 35/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9958 - loss: 0.0232 - val_accuracy: 0.8117 - val_loss: 1.0575\n",
      "Epoch 36/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0201 - val_accuracy: 0.8100 - val_loss: 1.0059\n",
      "Epoch 37/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9968 - loss: 0.0165 - val_accuracy: 0.8113 - val_loss: 1.1012\n",
      "Epoch 38/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9977 - loss: 0.0135 - val_accuracy: 0.8163 - val_loss: 1.1228\n",
      "Epoch 39/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9962 - loss: 0.0172 - val_accuracy: 0.8197 - val_loss: 1.0672\n",
      "Epoch 40/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9948 - loss: 0.0206 - val_accuracy: 0.8170 - val_loss: 1.0505\n",
      "Epoch 41/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9953 - loss: 0.0216 - val_accuracy: 0.8163 - val_loss: 0.9886\n",
      "Epoch 42/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9959 - loss: 0.0181 - val_accuracy: 0.8093 - val_loss: 1.1156\n",
      "Epoch 43/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9926 - loss: 0.0345 - val_accuracy: 0.8187 - val_loss: 0.9043\n",
      "Epoch 44/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9950 - loss: 0.0220 - val_accuracy: 0.8163 - val_loss: 0.9947\n",
      "Epoch 45/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9974 - loss: 0.0134 - val_accuracy: 0.8200 - val_loss: 1.1290\n",
      "Epoch 46/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9979 - loss: 0.0108 - val_accuracy: 0.8177 - val_loss: 1.1400\n",
      "Epoch 47/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.8090 - val_loss: 1.3043\n",
      "Epoch 48/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9973 - loss: 0.0122 - val_accuracy: 0.8133 - val_loss: 1.2551\n",
      "Epoch 49/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.9990 - loss: 0.0061 - val_accuracy: 0.8120 - val_loss: 1.3209\n",
      "Epoch 50/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.8150 - val_loss: 1.3368\n",
      "Epoch 51/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9954 - loss: 0.0184 - val_accuracy: 0.8163 - val_loss: 1.2900\n",
      "Epoch 52/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9967 - loss: 0.0126 - val_accuracy: 0.8230 - val_loss: 1.1959\n",
      "Epoch 53/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9984 - loss: 0.0075 - val_accuracy: 0.8187 - val_loss: 1.3576\n",
      "Epoch 54/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.8230 - val_loss: 1.3225\n",
      "Epoch 55/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 0.8180 - val_loss: 1.4391\n",
      "Epoch 56/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.8193 - val_loss: 1.4020\n",
      "Epoch 57/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.8190 - val_loss: 1.5002\n",
      "Epoch 58/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9999 - loss: 9.7161e-04 - val_accuracy: 0.8203 - val_loss: 1.5739\n",
      "Epoch 59/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8213 - val_loss: 1.6402\n",
      "Epoch 60/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.8217 - val_loss: 1.6855\n",
      "Epoch 61/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 9.3868e-04 - val_accuracy: 0.8213 - val_loss: 1.7435\n",
      "Epoch 62/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.8220 - val_loss: 1.7606\n",
      "Epoch 63/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.8187 - val_loss: 1.7732\n",
      "Epoch 64/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.8173 - val_loss: 1.3568\n",
      "Epoch 65/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9956 - loss: 0.0178 - val_accuracy: 0.8000 - val_loss: 1.1434\n",
      "Epoch 66/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.9962 - loss: 0.0152 - val_accuracy: 0.8113 - val_loss: 1.2141\n",
      "Epoch 67/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.9952 - loss: 0.0182 - val_accuracy: 0.8167 - val_loss: 1.1944\n",
      "Epoch 68/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 0.8200 - val_loss: 1.4158\n",
      "Epoch 69/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.8177 - val_loss: 1.4950\n",
      "Epoch 70/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.8173 - val_loss: 1.5989\n",
      "Epoch 71/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8180 - val_loss: 1.6437\n",
      "Epoch 72/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8183 - val_loss: 1.6759\n",
      "Epoch 73/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.8173 - val_loss: 1.7030\n",
      "Epoch 74/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.8173 - val_loss: 1.7461\n",
      "Epoch 75/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.8157 - val_loss: 1.7959\n",
      "Epoch 76/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 7.3234e-04 - val_accuracy: 0.8153 - val_loss: 1.8582\n",
      "Epoch 77/77\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8140 - val_loss: 1.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm modeller ve dosyalar başarıyla kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "# train_nlp.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# --- AYARLAR ---\n",
    "VOCAB_SIZE = 5000    # En çok kullanılan 5000 kelime\n",
    "MAX_LEN = 200        # Yorumun max uzunluğu (kelime)\n",
    "EMBEDDING_DIM = 64   # Vektör boyutu\n",
    "SAMPLE_SIZE = 15000  # Hızlı eğitim için veriyi kısıtlayalım (İstersen artırabilirsin)\n",
    "\n",
    "# 1. Veri Yükleme ve Temizleme\n",
    "print(\"Veri yükleniyor...\")\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# Etiketleri sayıya çevir (positive->1, negative->0)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Temizleme Fonksiyonu\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', '', text) # HTML taglerini sil\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Özel karakterleri sil\n",
    "    return text\n",
    "\n",
    "df['review'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Hız için örneklem al\n",
    "df = df.sample(SAMPLE_SIZE, random_state=42)\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Eğitim/Test Ayrımı\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- MODEL 1: KLASİK (TF-IDF + LOGISTIC REGRESSION) ---\n",
    "print(\"Model 1 (Klasik) eğitiliyor...\")\n",
    "tfidf = TfidfVectorizer(max_features=VOCAB_SIZE)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Başarı Skoru\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "print(f\"Klasik Model Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Kaydet\n",
    "joblib.dump(lr_model, \"nlp_classic_model.pkl\")\n",
    "joblib.dump(tfidf, \"nlp_tfidf.pkl\")\n",
    "\n",
    "# --- MODEL 2: DEEP LEARNING (LSTM) ---\n",
    "print(\"Model 2 (Deep Learning) eğitiliyor...\")\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# LSTM Mimarisi\n",
    "model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Eğit\n",
    "model.fit(X_train_pad, y_train, epochs=77, batch_size=64, validation_data=(X_test_pad, y_test), verbose=1)\n",
    "\n",
    "# Kaydet\n",
    "model.save(\"nlp_dl_model.h5\")\n",
    "joblib.dump(tokenizer, \"nlp_tokenizer.pkl\")\n",
    "\n",
    "print(\"Tüm modeller ve dosyalar başarıyla kaydedildi!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
