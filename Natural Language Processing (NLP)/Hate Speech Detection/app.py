# app.py
import streamlit as st
import joblib
import re
import string

# Modeli YÃ¼kle
try:
    model = joblib.load('src/hate_speech_model.pkl')
except:
    st.error("Model dosyasÄ± bulunamadÄ±. LÃ¼tfen 'train_model.py' dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n.")
    st.stop()

# Temizleme Fonksiyonu (EÄŸitimdeki ile aynÄ± mantÄ±kta olmalÄ±)
def clean_text(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

# Sayfa TasarÄ±mÄ±
st.set_page_config(page_title="Hate Speech Detection", page_icon="ğŸš«")

st.title("ğŸš« Hate Speech Detection")
st.markdown("Bu uygulama, girilen metnin **Nefret SÃ¶ylemi**, **SaldÄ±rgan Dil** veya **Temiz** olup olmadÄ±ÄŸÄ±nÄ± tespit eder.")
st.info("Not: Model Ä°ngilizce tweet veri seti Ã¼zerinde eÄŸitilmiÅŸtir.")

# KullanÄ±cÄ± GiriÅŸi
user_input = st.text_area("Analiz edilecek metni giriniz:", height=100, placeholder="Type something here...")

if st.button("Analiz Et"):
    if user_input:
        # Metni temizle
        cleaned_input = clean_text(user_input)
        
        # Tahmin yap
        prediction = model.predict([cleaned_input])[0]
        
        # Sonucu Ekrana Bas
        # Class 0: Hate Speech, 1: Offensive Language, 2: Neither
        
        if prediction == 0:
            st.error("SONUÃ‡: ğŸ¤¬ Hate Speech (Nefret SÃ¶ylemi) Tespit Edildi!")
            st.image("https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExM2Q4NzE4.../giphy.gif", width=100) # Opsiyonel gÃ¶rsel
        elif prediction == 1:
            st.warning("SONUÃ‡: ğŸ˜¡ Offensive Language (SaldÄ±rgan Dil)")
        else:
            st.success("SONUÃ‡: âœ… Neither (Temiz / NÃ¶tr)")
            
    else:
        st.write("LÃ¼tfen bir metin giriniz.")